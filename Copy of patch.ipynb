{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12AEoKfQgucgd2X7J2xLjHIMOB1uvUINv","timestamp":1663921724678}],"collapsed_sections":[],"mount_file_id":"12AEoKfQgucgd2X7J2xLjHIMOB1uvUINv","authorship_tag":"ABX9TyO1dHZq+lmWtAp8u/yWmo5M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnQZBP5RzVAR","executionInfo":{"status":"ok","timestamp":1663835674101,"user_tz":-330,"elapsed":4722,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"c5f34d3d-0ab8-412d-9177-447fe2a00add"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting patchify\n","  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.21.6)\n","Installing collected packages: patchify\n","Successfully installed patchify-0.2.3\n"]}],"source":["pip install patchify"]},{"cell_type":"code","source":["from PIL import Image\n","from numpy import asarray\n","from patchify import patchify\n","import cv2\n","import numpy as np\n","from patchify import patchify\n","from PIL import Image\n","import tensorflow as tf\n"],"metadata":{"id":"dsvU40NNUVm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qk45jau8UjeJ","executionInfo":{"status":"ok","timestamp":1663835700797,"user_tz":-330,"elapsed":14733,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"869df74a-05be-431b-b24e-53488e91493c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["num_classes = 2\n","input_shape = (280,280,3)"],"metadata":{"id":"qwGNFzIF6Wgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","Normal = glob.glob('/content/drive/MyDrive/Pitt/Cookie/spectogram/Normal_spec/*.*')\n","Dimentia = glob.glob('/content/drive/MyDrive/Pitt/Cookie/spectogram/dimentia_spec/*.*')\n","\n","\n","data = []\n","labels = []\n","\n","for i in Normal:   \n","    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n","    target_size= (280,280))\n","    image=np.array(image)\n","    data.append(image)\n","    labels.append(0)\n","for i in Dimentia:   \n","    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n","    target_size= (280,280))\n","    image=np.array(image)\n","    data.append(image)\n","    labels.append(1)\n","\n","\n","data = np.array(data)\n","labels = np.array(labels)\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.2,\n","                                                random_state=42)"],"metadata":{"id":"vQra0BQtyugk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches"],"metadata":{"id":"tzRLByhM0jjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.001\n","weight_decay = 0.0001\n","batch_size = 256\n","num_epochs = 50\n","image_size = 72  # We'll resize input images to this size\n","patch_size = 6  # Size of the patches to be extract from the input images\n","num_patches = (image_size // patch_size) ** 2\n","projection_dim = 64\n","num_heads = 4\n","transformer_units = [\n","    projection_dim * 2,\n","    projection_dim,\n","]  # Size of the transformer layers\n","transformer_layers = 8\n","mlp_head_units = [2048, 1024] "],"metadata":{"id":"PO_DO4YQytCE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x"],"metadata":{"id":"ipBFj15-2Ka3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(72, 72),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(factor=0.02),\n","        layers.RandomZoom(\n","            height_factor=0.2, width_factor=0.2\n","        ),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","data_augmentation.layers[0].adapt(X_train)"],"metadata":{"id":"w-okWhOP0Ps-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n"," \n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded"],"metadata":{"id":"0iB01BlZ187p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    augmented = data_augmentation(inputs)\n","    # Create patches.\n","    patches = Patches(patch_size)(augmented)\n","    # Encode patches.\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # Create a multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Create a [batch_size, projection_dim] tensor.\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","    # Classify outputs.\n","    logits = layers.Dense(num_classes)(features)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","    return model"],"metadata":{"id":"hxZMmGFT3oiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_experiment(model):\n","    optimizer = tfa.optimizers.AdamW(\n","        learning_rate=learning_rate, weight_decay=weight_decay\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","      \n","        ],\n","    )\n","\n","    ##checkpoint_filepath = \"/tmp/checkpoint\"\n","    ##checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","        ##checkpoint_filepath,\n","        ##monitor=\"val_accuracy\",\n","        ##save_best_only=True,\n","        ##save_weights_only=True,\n","    #)\n","\n","    history = model.fit(\n","    x=X_train,\n","    y=ytrain,\n","    batch_size=batch_size,\n","    epochs=num_epochs,\n","    validation_split=0.1,)\n","\n","\n","\n","\n","vit_classifier = create_vit_classifier()\n","history = run_experiment(vit_classifier)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qvt8Ggu3zXb","executionInfo":{"status":"ok","timestamp":1663836211058,"user_tz":-330,"elapsed":548,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"25ff86d7-f915-4147-e599-c3e84cfdc60a"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","1/1 [==============================] - 20s 20s/step - loss: 1.8162 - accuracy: 0.4700 - top-5-accuracy: 1.0000 - val_loss: 22.3192 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 2/50\n","1/1 [==============================] - 6s 6s/step - loss: 25.1343 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 5.2433 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 3/50\n","1/1 [==============================] - 6s 6s/step - loss: 7.6459 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 6.0781 - val_accuracy: 0.1667 - val_top-5-accuracy: 1.0000\n","Epoch 4/50\n","1/1 [==============================] - 8s 8s/step - loss: 2.7348 - accuracy: 0.3500 - top-5-accuracy: 1.0000 - val_loss: 1.3379 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 5/50\n","1/1 [==============================] - 6s 6s/step - loss: 3.5497 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 1.2368 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 6/50\n","1/1 [==============================] - 7s 7s/step - loss: 2.0345 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 7/50\n","1/1 [==============================] - 6s 6s/step - loss: 1.1156 - accuracy: 0.7700 - top-5-accuracy: 1.0000 - val_loss: 2.7325 - val_accuracy: 0.1667 - val_top-5-accuracy: 1.0000\n","Epoch 8/50\n","1/1 [==============================] - 6s 6s/step - loss: 1.5648 - accuracy: 0.4300 - top-5-accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 9/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8261 - accuracy: 0.6800 - top-5-accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 10/50\n","1/1 [==============================] - 6s 6s/step - loss: 1.3134 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 11/50\n","1/1 [==============================] - 6s 6s/step - loss: 1.1176 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 12/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8578 - accuracy: 0.7500 - top-5-accuracy: 1.0000 - val_loss: 1.2822 - val_accuracy: 0.1667 - val_top-5-accuracy: 1.0000\n","Epoch 13/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.9549 - accuracy: 0.5700 - top-5-accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.2500 - val_top-5-accuracy: 1.0000\n","Epoch 14/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8456 - accuracy: 0.6100 - top-5-accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 15/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8044 - accuracy: 0.7400 - top-5-accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 16/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8957 - accuracy: 0.7500 - top-5-accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 17/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.9042 - accuracy: 0.7200 - top-5-accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 18/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8084 - accuracy: 0.7400 - top-5-accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 19/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7332 - accuracy: 0.7200 - top-5-accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.6667 - val_top-5-accuracy: 1.0000\n","Epoch 20/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6809 - accuracy: 0.6500 - top-5-accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 21/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6476 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 22/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7392 - accuracy: 0.7600 - top-5-accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 23/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7949 - accuracy: 0.7800 - top-5-accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 24/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8217 - accuracy: 0.7500 - top-5-accuracy: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.7500 - val_top-5-accuracy: 1.0000\n","Epoch 25/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6683 - accuracy: 0.7400 - top-5-accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.6667 - val_top-5-accuracy: 1.0000\n","Epoch 26/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7958 - accuracy: 0.6500 - top-5-accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.7500 - val_top-5-accuracy: 1.0000\n","Epoch 27/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8831 - accuracy: 0.6800 - top-5-accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.7500 - val_top-5-accuracy: 1.0000\n","Epoch 28/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6225 - accuracy: 0.7400 - top-5-accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 29/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6130 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 30/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7261 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 31/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.8248 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 32/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5193 - accuracy: 0.7700 - top-5-accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 33/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5071 - accuracy: 0.7800 - top-5-accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 34/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6219 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 35/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6317 - accuracy: 0.7900 - top-5-accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 36/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5533 - accuracy: 0.7500 - top-5-accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 37/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6049 - accuracy: 0.7800 - top-5-accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 38/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6214 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 39/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6281 - accuracy: 0.7400 - top-5-accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 40/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5449 - accuracy: 0.7900 - top-5-accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 41/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.6255 - accuracy: 0.7600 - top-5-accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 42/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7410 - accuracy: 0.7300 - top-5-accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 43/50\n","1/1 [==============================] - 7s 7s/step - loss: 0.7070 - accuracy: 0.6500 - top-5-accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 44/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.7151 - accuracy: 0.7600 - top-5-accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 45/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5772 - accuracy: 0.7500 - top-5-accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 46/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5618 - accuracy: 0.7900 - top-5-accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 47/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5845 - accuracy: 0.8000 - top-5-accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 48/50\n","1/1 [==============================] - 7s 7s/step - loss: 0.6312 - accuracy: 0.7900 - top-5-accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 49/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.6821 - accuracy: 0.7700 - top-5-accuracy: 1.0000 - val_loss: 0.5472 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n","Epoch 50/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.5939 - accuracy: 0.7700 - top-5-accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.8333 - val_top-5-accuracy: 1.0000\n"]}]},{"cell_type":"code","source":[" _, accuracy, top_5_accuracy = vit_classifier.evaluate(X_test, ytest)\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0-vSbtu4CRz","executionInfo":{"status":"ok","timestamp":1663836211062,"user_tz":-330,"elapsed":0,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"4ebda285-6b34-42a7-de0c-857e914e6dc6"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 591ms/step - loss: 0.5593 - accuracy: 0.8571 - top-5-accuracy: 1.0000\n","Test accuracy: 85.71%\n","Test top 5 accuracy: 100.0%\n"]}]},{"cell_type":"code","source":["pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ddztIAXc1xbP","executionInfo":{"status":"ok","timestamp":1663835828538,"user_tz":-330,"elapsed":8227,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"9bc2b002-4017-4163-d84f-8975d9bdcf04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.18.0\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","p_pred = vit_classifier.predict(X_test)\n","# [1. 0.01 0.91 0.87 0.06 0.95 0.24 0.58 0.78 ...\n","\n","# extract the predicted class labels\n","import numpy as np\n","rounded_labels=np.argmax(p_pred, axis=1)\n","print(accuracy_score(ytest, rounded_labels))\n","\n","# [1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 ...\n","\n","##print(confusion_matrix(ytest, y_pred))\n","# [[13  1]\n","#  [ 2  9]]\n","\n","##print(classification_report(ytest, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWeKkMfCzxAn","executionInfo":{"status":"ok","timestamp":1663821538897,"user_tz":-330,"elapsed":2267,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"887ec15f-cb75-430a-8b56-dee8eae33638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8571428571428571\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","metrics.confusion_matrix(ytest, rounded_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5H78m9Tddzy","executionInfo":{"status":"ok","timestamp":1663821546811,"user_tz":-330,"elapsed":371,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"6ac4e1cf-d0a5-414d-f715-e20230c9e94b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  4],\n","       [ 0, 24]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["vit_classifier.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE56dxu6NWbn","executionInfo":{"status":"ok","timestamp":1663514834449,"user_tz":-330,"elapsed":1145,"user":{"displayName":"dimentia research","userId":"01661094314832209006"}},"outputId":"58d8d920-a75a-4399-8c95-5281410640b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 280, 280, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," data_augmentation (Sequential)  (None, 72, 72, 3)   7           ['input_5[0][0]']                \n","                                                                                                  \n"," patches_4 (Patches)            (None, None, 108)    0           ['data_augmentation[1][0]']      \n","                                                                                                  \n"," patch_encoder_4 (PatchEncoder)  (None, 144, 64)     16192       ['patches_4[0][0]']              \n","                                                                                                  \n"," layer_normalization_68 (LayerN  (None, 144, 64)     128         ['patch_encoder_4[0][0]']        \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_32 (Multi  (None, 144, 64)     66368       ['layer_normalization_68[0][0]', \n"," HeadAttention)                                                   'layer_normalization_68[0][0]'] \n","                                                                                                  \n"," add_64 (Add)                   (None, 144, 64)      0           ['multi_head_attention_32[0][0]',\n","                                                                  'patch_encoder_4[0][0]']        \n","                                                                                                  \n"," layer_normalization_69 (LayerN  (None, 144, 64)     128         ['add_64[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_81 (Dense)               (None, 144, 128)     8320        ['layer_normalization_69[0][0]'] \n","                                                                                                  \n"," dropout_76 (Dropout)           (None, 144, 128)     0           ['dense_81[0][0]']               \n","                                                                                                  \n"," dense_82 (Dense)               (None, 144, 64)      8256        ['dropout_76[0][0]']             \n","                                                                                                  \n"," dropout_77 (Dropout)           (None, 144, 64)      0           ['dense_82[0][0]']               \n","                                                                                                  \n"," add_65 (Add)                   (None, 144, 64)      0           ['dropout_77[0][0]',             \n","                                                                  'add_64[0][0]']                 \n","                                                                                                  \n"," layer_normalization_70 (LayerN  (None, 144, 64)     128         ['add_65[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_33 (Multi  (None, 144, 64)     66368       ['layer_normalization_70[0][0]', \n"," HeadAttention)                                                   'layer_normalization_70[0][0]'] \n","                                                                                                  \n"," add_66 (Add)                   (None, 144, 64)      0           ['multi_head_attention_33[0][0]',\n","                                                                  'add_65[0][0]']                 \n","                                                                                                  \n"," layer_normalization_71 (LayerN  (None, 144, 64)     128         ['add_66[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_83 (Dense)               (None, 144, 128)     8320        ['layer_normalization_71[0][0]'] \n","                                                                                                  \n"," dropout_78 (Dropout)           (None, 144, 128)     0           ['dense_83[0][0]']               \n","                                                                                                  \n"," dense_84 (Dense)               (None, 144, 64)      8256        ['dropout_78[0][0]']             \n","                                                                                                  \n"," dropout_79 (Dropout)           (None, 144, 64)      0           ['dense_84[0][0]']               \n","                                                                                                  \n"," add_67 (Add)                   (None, 144, 64)      0           ['dropout_79[0][0]',             \n","                                                                  'add_66[0][0]']                 \n","                                                                                                  \n"," layer_normalization_72 (LayerN  (None, 144, 64)     128         ['add_67[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_34 (Multi  (None, 144, 64)     66368       ['layer_normalization_72[0][0]', \n"," HeadAttention)                                                   'layer_normalization_72[0][0]'] \n","                                                                                                  \n"," add_68 (Add)                   (None, 144, 64)      0           ['multi_head_attention_34[0][0]',\n","                                                                  'add_67[0][0]']                 \n","                                                                                                  \n"," layer_normalization_73 (LayerN  (None, 144, 64)     128         ['add_68[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_85 (Dense)               (None, 144, 128)     8320        ['layer_normalization_73[0][0]'] \n","                                                                                                  \n"," dropout_80 (Dropout)           (None, 144, 128)     0           ['dense_85[0][0]']               \n","                                                                                                  \n"," dense_86 (Dense)               (None, 144, 64)      8256        ['dropout_80[0][0]']             \n","                                                                                                  \n"," dropout_81 (Dropout)           (None, 144, 64)      0           ['dense_86[0][0]']               \n","                                                                                                  \n"," add_69 (Add)                   (None, 144, 64)      0           ['dropout_81[0][0]',             \n","                                                                  'add_68[0][0]']                 \n","                                                                                                  \n"," layer_normalization_74 (LayerN  (None, 144, 64)     128         ['add_69[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_35 (Multi  (None, 144, 64)     66368       ['layer_normalization_74[0][0]', \n"," HeadAttention)                                                   'layer_normalization_74[0][0]'] \n","                                                                                                  \n"," add_70 (Add)                   (None, 144, 64)      0           ['multi_head_attention_35[0][0]',\n","                                                                  'add_69[0][0]']                 \n","                                                                                                  \n"," layer_normalization_75 (LayerN  (None, 144, 64)     128         ['add_70[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_87 (Dense)               (None, 144, 128)     8320        ['layer_normalization_75[0][0]'] \n","                                                                                                  \n"," dropout_82 (Dropout)           (None, 144, 128)     0           ['dense_87[0][0]']               \n","                                                                                                  \n"," dense_88 (Dense)               (None, 144, 64)      8256        ['dropout_82[0][0]']             \n","                                                                                                  \n"," dropout_83 (Dropout)           (None, 144, 64)      0           ['dense_88[0][0]']               \n","                                                                                                  \n"," add_71 (Add)                   (None, 144, 64)      0           ['dropout_83[0][0]',             \n","                                                                  'add_70[0][0]']                 \n","                                                                                                  \n"," layer_normalization_76 (LayerN  (None, 144, 64)     128         ['add_71[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_36 (Multi  (None, 144, 64)     66368       ['layer_normalization_76[0][0]', \n"," HeadAttention)                                                   'layer_normalization_76[0][0]'] \n","                                                                                                  \n"," add_72 (Add)                   (None, 144, 64)      0           ['multi_head_attention_36[0][0]',\n","                                                                  'add_71[0][0]']                 \n","                                                                                                  \n"," layer_normalization_77 (LayerN  (None, 144, 64)     128         ['add_72[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_89 (Dense)               (None, 144, 128)     8320        ['layer_normalization_77[0][0]'] \n","                                                                                                  \n"," dropout_84 (Dropout)           (None, 144, 128)     0           ['dense_89[0][0]']               \n","                                                                                                  \n"," dense_90 (Dense)               (None, 144, 64)      8256        ['dropout_84[0][0]']             \n","                                                                                                  \n"," dropout_85 (Dropout)           (None, 144, 64)      0           ['dense_90[0][0]']               \n","                                                                                                  \n"," add_73 (Add)                   (None, 144, 64)      0           ['dropout_85[0][0]',             \n","                                                                  'add_72[0][0]']                 \n","                                                                                                  \n"," layer_normalization_78 (LayerN  (None, 144, 64)     128         ['add_73[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_37 (Multi  (None, 144, 64)     66368       ['layer_normalization_78[0][0]', \n"," HeadAttention)                                                   'layer_normalization_78[0][0]'] \n","                                                                                                  \n"," add_74 (Add)                   (None, 144, 64)      0           ['multi_head_attention_37[0][0]',\n","                                                                  'add_73[0][0]']                 \n","                                                                                                  \n"," layer_normalization_79 (LayerN  (None, 144, 64)     128         ['add_74[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_91 (Dense)               (None, 144, 128)     8320        ['layer_normalization_79[0][0]'] \n","                                                                                                  \n"," dropout_86 (Dropout)           (None, 144, 128)     0           ['dense_91[0][0]']               \n","                                                                                                  \n"," dense_92 (Dense)               (None, 144, 64)      8256        ['dropout_86[0][0]']             \n","                                                                                                  \n"," dropout_87 (Dropout)           (None, 144, 64)      0           ['dense_92[0][0]']               \n","                                                                                                  \n"," add_75 (Add)                   (None, 144, 64)      0           ['dropout_87[0][0]',             \n","                                                                  'add_74[0][0]']                 \n","                                                                                                  \n"," layer_normalization_80 (LayerN  (None, 144, 64)     128         ['add_75[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_38 (Multi  (None, 144, 64)     66368       ['layer_normalization_80[0][0]', \n"," HeadAttention)                                                   'layer_normalization_80[0][0]'] \n","                                                                                                  \n"," add_76 (Add)                   (None, 144, 64)      0           ['multi_head_attention_38[0][0]',\n","                                                                  'add_75[0][0]']                 \n","                                                                                                  \n"," layer_normalization_81 (LayerN  (None, 144, 64)     128         ['add_76[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_93 (Dense)               (None, 144, 128)     8320        ['layer_normalization_81[0][0]'] \n","                                                                                                  \n"," dropout_88 (Dropout)           (None, 144, 128)     0           ['dense_93[0][0]']               \n","                                                                                                  \n"," dense_94 (Dense)               (None, 144, 64)      8256        ['dropout_88[0][0]']             \n","                                                                                                  \n"," dropout_89 (Dropout)           (None, 144, 64)      0           ['dense_94[0][0]']               \n","                                                                                                  \n"," add_77 (Add)                   (None, 144, 64)      0           ['dropout_89[0][0]',             \n","                                                                  'add_76[0][0]']                 \n","                                                                                                  \n"," layer_normalization_82 (LayerN  (None, 144, 64)     128         ['add_77[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_39 (Multi  (None, 144, 64)     66368       ['layer_normalization_82[0][0]', \n"," HeadAttention)                                                   'layer_normalization_82[0][0]'] \n","                                                                                                  \n"," add_78 (Add)                   (None, 144, 64)      0           ['multi_head_attention_39[0][0]',\n","                                                                  'add_77[0][0]']                 \n","                                                                                                  \n"," layer_normalization_83 (LayerN  (None, 144, 64)     128         ['add_78[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_95 (Dense)               (None, 144, 128)     8320        ['layer_normalization_83[0][0]'] \n","                                                                                                  \n"," dropout_90 (Dropout)           (None, 144, 128)     0           ['dense_95[0][0]']               \n","                                                                                                  \n"," dense_96 (Dense)               (None, 144, 64)      8256        ['dropout_90[0][0]']             \n","                                                                                                  \n"," dropout_91 (Dropout)           (None, 144, 64)      0           ['dense_96[0][0]']               \n","                                                                                                  \n"," add_79 (Add)                   (None, 144, 64)      0           ['dropout_91[0][0]',             \n","                                                                  'add_78[0][0]']                 \n","                                                                                                  \n"," layer_normalization_84 (LayerN  (None, 144, 64)     128         ['add_79[0][0]']                 \n"," ormalization)                                                                                    \n","                                                                                                  \n"," flatten_4 (Flatten)            (None, 9216)         0           ['layer_normalization_84[0][0]'] \n","                                                                                                  \n"," dropout_92 (Dropout)           (None, 9216)         0           ['flatten_4[0][0]']              \n","                                                                                                  \n"," dense_97 (Dense)               (None, 2048)         18876416    ['dropout_92[0][0]']             \n","                                                                                                  \n"," dropout_93 (Dropout)           (None, 2048)         0           ['dense_97[0][0]']               \n","                                                                                                  \n"," dense_98 (Dense)               (None, 1024)         2098176     ['dropout_93[0][0]']             \n","                                                                                                  \n"," dropout_94 (Dropout)           (None, 1024)         0           ['dense_98[0][0]']               \n","                                                                                                  \n"," dense_99 (Dense)               (None, 2)            2050        ['dropout_94[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 21,658,569\n","Trainable params: 21,658,562\n","Non-trainable params: 7\n","__________________________________________________________________________________________________\n"]}]}]}